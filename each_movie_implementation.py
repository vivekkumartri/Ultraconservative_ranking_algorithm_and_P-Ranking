# -*- coding: utf-8 -*-
"""Each_Movie_implementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XVm1Qg7cn9Z6hcslUApj3Sb-nZRwHc3l

# data preprocessing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

vote=pd.read_csv("/home/22n0457/Vote.txt",names=['person id','movie id','score','weight','modified date'],sep='\t')

movie_df=pd.read_csv("/home/22n0457/Movie.txt",names=['movie id','name','PR_URL','IMDb_URL','theater','theater release','video status','video release','action','animation','art_foreign','classic','comedy','drama','family','horror','romance','thriller'],sep='\t',encoding='latin-1')

person_df=pd.read_csv("/home/22n0457/Person.txt",names=['person id','age','gender','zip code'],sep='\t',encoding='latin-1')

df=vote.merge(movie_df,on='movie id')
df=df.merge(person_df,on='person id')

df.isnull().sum()

df.shape

#zip code theater release video release PR url imdb url has null entry so we drop that column
df.drop(columns=['PR_URL','IMDb_URL','theater release','video release','zip code'],inplace=True)

df['gender']=df['gender'].fillna(method='ffill')

df['video status']=df['video status'].fillna(method='ffill')

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

df.info()

df.drop(columns='modified date',inplace=True)

df.info()

df=pd.get_dummies(df,columns=['theater','video status','gender'])

def lowerstr(obj):
    return obj.lower()

df['name']=df['name'].apply(lowerstr)

df.reset_index(inplace=True)

df.drop(columns='index',inplace=True)

vote['sume']=[1 for i in range(vote.shape[0])]

vote['score']=vote['score']-0.5

vote.drop(columns=["weight","modified date"],inplace=True)

ci=[]
t=(vote.groupby(['person id']).count()['score']>100)
for j in t.index:
    if t[j]==False:
        ci.append(j)
data100=vote.pivot_table(index='movie id', columns='person id', values='score')
data100.drop(columns=ci,inplace=True)
data100.fillna(0,inplace=True)

np.savetxt('/home/22n0457/each100_new/data100.csv',data100, delimiter=',')

ci=[]
t=(vote.groupby(['person id']).count()['score']>200)
for j in t.index:
    if t[j]==False:
        ci.append(j)
data200=vote.pivot_table(index='movie id', columns='person id', values='score')
data200.drop(columns=ci,inplace=True)
data200.fillna(0,inplace=True)

np.savetxt('/home/22n0457/each200_new/data200.csv',data200, delimiter=',')

"""for more than 200 movie

# algorithm code

# Experiment
"""

w1_synthetic=[]
loss11=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss1,w1=algorithm.widrowhoff(x,y,400,0.001)
    loss11.append(loss1)
    w1_synthetic.append(w1)

np.savetxt('/home/22n0457/each100_new/loss1.csv',loss11, delimiter=',')
np.savetxt('/home/22n0457/each100_new/w1_synthetic.csv',w1_synthetic, delimiter=',')

w2_synthetic=[]
b2_synthetic=[]
loss21=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss2,w2,b2=algorithm.pranking(x,y,400)
    loss21.append(loss2)
    w2_synthetic.append(w2)
    b2_synthetic.append(b2)

np.savetxt('/home/22n0457/each100_new/loss2.csv',loss21, delimiter=',')
np.savetxt('/home/22n0457/each100_new/w2_synthetic.csv',w2_synthetic, delimiter=',')
#np.savetxt('/home/22n0457/each100_new/b2_synthetic.csv',b2_synthetic, delimiter=',')

loss31=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss3,m1=algorithm.uniformmulticlassalgo(x,y,400)
    loss31.append(loss3)

np.savetxt('/home/22n0457/each100_new/loss3.csv',loss31, delimiter=',')

loss41=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss4,m2=algorithm.worstmulticlassalgo(x,y,400)
    loss41.append(loss4)

np.savetxt('/home/22n0457/each100_new/loss4.csv',loss41, delimiter=',')

loss51=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss5,m3=algorithm.vimulticlassalgo(x,y,400)
    loss51.append(loss5)

np.savetxt('/home/22n0457/each100_new/loss5.csv',loss51, delimiter=',')

loss61=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss6,m4=algorithm.mira(x,y,400)
    loss61.append(loss6)

np.savetxt('/home/22n0457/each100_new/loss6.csv',loss61, delimiter=',')

w1_synthetic=[]
loss11=[]
for i in range(500):
    x=np.array(data200)
    y=np.array(data200.sample(axis='columns'))
    loss1,w1=algorithm.widrowhoff(x,y,400,0.001)
    loss11.append(loss1)
    w1_synthetic.append(w1)

np.savetxt('/home/22n0457/each200_new/loss1.csv',loss11, delimiter=',')
np.savetxt('/home/22n0457/each200_new/w1_synthetic.csv',w1_synthetic, delimiter=',')

w2_synthetic=[]
b2_synthetic=[]
loss21=[]
for i in range(500):
    x=np.array(data200)
    y=np.array(data200.sample(axis='columns'))
    loss2,w2,b2=algorithm.pranking(x,y,400)
    loss21.append(loss2)
    w2_synthetic.append(w2)
    b2_synthetic.append(b2)

np.savetxt('/home/22n0457/each200_new/loss2.csv',loss21, delimiter=',')
np.savetxt('/home/22n0457/each200_new/w2_synthetic.csv',w2_synthetic, delimiter=',')
#np.savetxt('/home/22n0457/each200_new/b2_synthetic.csv',b2_synthetic, delimiter=',')

loss31=[]
for i in range(500):
    x=np.array(data200)
    y=np.array(data200.sample(axis='columns'))
    loss3,m1=algorithm.uniformmulticlassalgo(x,y,400)
    loss31.append(loss3)
    np.savetxt(f'/home/22n0457/each200_new/m1_synthetic___{i}.csv',m1, delimiter=',')

np.savetxt('/home/22n0457/each200_new/loss3.csv',loss31, delimiter=',')

loss41=[]
for i in range(500):
    x=np.array(data200)
    y=np.array(data200.sample(axis='columns'))
    loss4,m2=algorithm.worstmulticlassalgo(x,y,400)
    loss41.append(loss4)
    np.savetxt(f'/home/22n0457/each200_new/m2_synthetic___{i}.csv',m2, delimiter=',')

np.savetxt('/home/22n0457/each200_new/loss4.csv',loss41, delimiter=',')

loss51=[]
for i in range(500):
    x=np.array(data200)
    y=np.array(data200.sample(axis='columns'))
    loss5,m3=algorithm.vimulticlassalgo(x,y,400)
    loss51.append(loss5)
    np.savetxt(f'/home/22n0457/each200_new/m3_synthetic___{i}.csv',m3, delimiter=',')

np.savetxt('/home/22n0457/each200_new/loss5.csv',loss51, delimiter=',')

loss61=[]
for i in range(500):
    x=np.array(data100)
    y=np.array(data100.sample(axis='columns'))
    loss6,m4=algorithm.mira(x,y,400)
    loss61.append(loss6)
    np.savetxt(f'/home/22n0457/each200_new/m4_synthetic___{i}.csv',m4, delimiter=',')

np.savetxt('/home/22n0457/each200_new/loss6.csv',loss61, delimiter=',')







